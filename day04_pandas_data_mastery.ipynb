{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 4: Pandas - Data Mastery \n",
                "\n",
                "Welcome to **Pandas**, the most powerful library for data manipulation in Python! If NumPy is the foundation, Pandas is the entire building where data science actually happens.\n",
                "\n",
                "### Why Pandas?\n",
                "- It provides **DataFrames** - spreadsheet-like structures for easy data handling.\n",
                "- It can handle **missing data** gracefully.\n",
                "- It offers powerful **grouping, merging, and aggregation** capabilities.\n",
                "- It's the go-to tool for **Exploratory Data Analysis (EDA)**.\n",
                "\n",
                "### Topics Covered:\n",
                "1. **Series & DataFrames**\n",
                "2. **Loading & Inspecting Data**\n",
                "3. **Handling Missing Values**\n",
                "4. **Filtering & Selection**\n",
                "5. **GroupBy & Aggregations**\n",
                "6. **Merging DataFrames**\n",
                "7. **The Apply Function**\n",
                "8. **Mini Project: Sales Analysis**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# First, let's import the essential libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Set display options for better readability\n",
                "pd.set_option('display.max_columns', 10)\n",
                "pd.set_option('display.width', 100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Series & DataFrames\n",
                "\n",
                "Pandas has two main data structures:\n",
                "- **Series**: A 1D labeled array (like a column in Excel)\n",
                "- **DataFrame**: A 2D labeled table (like a spreadsheet)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating a Series\n",
                "sales = pd.Series([250, 320, 180, 410], \n",
                "                  index=['Jan', 'Feb', 'Mar', 'Apr'],\n",
                "                  name='Monthly Sales')\n",
                "print(\"=== Series ===\")\n",
                "print(sales)\n",
                "print(f\"\\nType: {type(sales)}\")\n",
                "print(f\"Sum: ${sales.sum()}\")\n",
                "print(f\"Mean: ${sales.mean():.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Creating a DataFrame from a dictionary\n",
                "data = {\n",
                "    'Product': ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard'],\n",
                "    'Category': ['Electronics', 'Electronics', 'Electronics', 'Electronics', 'Accessories'],\n",
                "    'Price': [1200, 800, 450, 350, 75],\n",
                "    'Quantity': [50, 150, 80, 60, 200],\n",
                "    'Rating': [4.5, 4.8, 4.2, 4.0, 4.6]\n",
                "}\n",
                "\n",
                "df = pd.DataFrame(data)\n",
                "print(\"=== DataFrame ===\")\n",
                "print(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Loading & Inspecting Data\n",
                "\n",
                "In real-world scenarios, you'll load data from files. Let's create a sample dataset and learn inspection techniques."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Let's create a more realistic sales dataset\n",
                "np.random.seed(42)  # For reproducibility\n",
                "\n",
                "n_records = 100\n",
                "regions = ['North', 'South', 'East', 'West']\n",
                "products = ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Charger']\n",
                "salespeople = ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve']\n",
                "\n",
                "sales_data = pd.DataFrame({\n",
                "    'Date': pd.date_range(start='2024-01-01', periods=n_records, freq='D'),\n",
                "    'Region': np.random.choice(regions, n_records),\n",
                "    'Product': np.random.choice(products, n_records),\n",
                "    'Salesperson': np.random.choice(salespeople, n_records),\n",
                "    'Units_Sold': np.random.randint(1, 50, n_records),\n",
                "    'Unit_Price': np.random.choice([50, 100, 250, 500, 1000], n_records),\n",
                "    'Customer_Rating': np.random.choice([3.0, 3.5, 4.0, 4.5, 5.0, np.nan], n_records)  # Include some NaN\n",
                "})\n",
                "\n",
                "# Calculate Revenue\n",
                "sales_data['Revenue'] = sales_data['Units_Sold'] * sales_data['Unit_Price']\n",
                "\n",
                "print(\"Dataset created! Let's inspect it...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Essential inspection methods\n",
                "print(\"=== First 5 Rows (head) ===\")\n",
                "print(sales_data.head())\n",
                "\n",
                "print(\"\\n=== Last 3 Rows (tail) ===\")\n",
                "print(sales_data.tail(3))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DataFrame structure and info\n",
                "print(\"=== Shape ===\")\n",
                "print(f\"Rows: {sales_data.shape[0]}, Columns: {sales_data.shape[1]}\")\n",
                "\n",
                "print(\"\\n=== Column Names ===\")\n",
                "print(sales_data.columns.tolist())\n",
                "\n",
                "print(\"\\n=== Data Types ===\")\n",
                "print(sales_data.dtypes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Comprehensive info and statistics\n",
                "print(\"=== Info ===\")\n",
                "print(sales_data.info())\n",
                "\n",
                "print(\"\\n=== Statistical Summary ===\")\n",
                "print(sales_data.describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Handling Missing Values\n",
                "\n",
                "Real-world data is messy. Missing values (`NaN`) are common. Pandas provides tools to detect and handle them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Detecting missing values\n",
                "print(\"=== Missing Values Count ===\")\n",
                "print(sales_data.isnull().sum())\n",
                "\n",
                "print(f\"\\nTotal missing: {sales_data.isnull().sum().sum()}\")\n",
                "print(f\"Percentage missing in Customer_Rating: {sales_data['Customer_Rating'].isnull().mean() * 100:.1f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Method 1: Drop rows with missing values\n",
                "df_dropped = sales_data.dropna()\n",
                "print(f\"Original rows: {len(sales_data)}\")\n",
                "print(f\"After dropna: {len(df_dropped)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Method 2: Fill missing values\n",
                "# Option A: Fill with a constant\n",
                "df_filled_constant = sales_data.copy()\n",
                "df_filled_constant['Customer_Rating'] = df_filled_constant['Customer_Rating'].fillna(0)\n",
                "\n",
                "# Option B: Fill with mean (most common approach)\n",
                "df_filled_mean = sales_data.copy()\n",
                "mean_rating = df_filled_mean['Customer_Rating'].mean()\n",
                "df_filled_mean['Customer_Rating'] = df_filled_mean['Customer_Rating'].fillna(mean_rating)\n",
                "\n",
                "print(f\"Mean rating used for filling: {mean_rating:.2f}\")\n",
                "print(f\"Missing values after fillna: {df_filled_mean['Customer_Rating'].isnull().sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Filtering & Selection\n",
                "\n",
                "Selecting specific rows and columns is fundamental to data analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Selecting columns\n",
                "print(\"=== Single Column (Series) ===\")\n",
                "print(sales_data['Product'].head())\n",
                "\n",
                "print(\"\\n=== Multiple Columns (DataFrame) ===\")\n",
                "print(sales_data[['Product', 'Revenue', 'Region']].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Filtering rows with conditions\n",
                "print(\"=== High Revenue Sales (> $5000) ===\")\n",
                "high_revenue = sales_data[sales_data['Revenue'] > 5000]\n",
                "print(high_revenue.head())\n",
                "print(f\"\\nCount: {len(high_revenue)} transactions\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Multiple conditions (AND: &, OR: |)\n",
                "print(\"=== North Region + High Rating (>= 4.5) ===\")\n",
                "filtered = sales_data[(sales_data['Region'] == 'North') & (sales_data['Customer_Rating'] >= 4.5)]\n",
                "print(filtered[['Region', 'Product', 'Revenue', 'Customer_Rating']].head())\n",
                "print(f\"\\nCount: {len(filtered)} transactions\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using .loc (label-based) and .iloc (index-based)\n",
                "print(\"=== Using .loc (by label) ===\")\n",
                "print(sales_data.loc[0:4, ['Product', 'Region', 'Revenue']])\n",
                "\n",
                "print(\"\\n=== Using .iloc (by position) ===\")\n",
                "print(sales_data.iloc[0:5, [2, 1, 7]])  # First 5 rows, columns at positions 2, 1, 7"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. GroupBy & Aggregations\n",
                "\n",
                "One of the most powerful features! Group data and calculate aggregate statistics."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple groupby with single aggregation\n",
                "print(\"=== Total Revenue by Region ===\")\n",
                "revenue_by_region = sales_data.groupby('Region')['Revenue'].sum().sort_values(ascending=False)\n",
                "print(revenue_by_region)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Multiple aggregations with .agg()\n",
                "print(\"=== Revenue Stats by Region ===\")\n",
                "region_stats = sales_data.groupby('Region')['Revenue'].agg(['sum', 'mean', 'count', 'max'])\n",
                "region_stats.columns = ['Total', 'Average', 'Count', 'Max']\n",
                "print(region_stats)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Grouping by multiple columns\n",
                "print(\"=== Revenue by Region & Product ===\")\n",
                "region_product = sales_data.groupby(['Region', 'Product'])['Revenue'].sum().unstack(fill_value=0)\n",
                "print(region_product)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Top performing salespeople\n",
                "print(\"=== Top Salespeople by Total Revenue ===\")\n",
                "top_salespeople = sales_data.groupby('Salesperson').agg({\n",
                "    'Revenue': 'sum',\n",
                "    'Units_Sold': 'sum',\n",
                "    'Customer_Rating': 'mean'\n",
                "}).round(2).sort_values('Revenue', ascending=False)\n",
                "print(top_salespeople)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Merging DataFrames\n",
                "\n",
                "Combine data from multiple sources - similar to SQL JOINs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create additional DataFrames for merging examples\n",
                "product_info = pd.DataFrame({\n",
                "    'Product': ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Charger'],\n",
                "    'Category': ['Electronics', 'Electronics', 'Electronics', 'Audio', 'Accessories'],\n",
                "    'Cost': [800, 500, 300, 30, 10]\n",
                "})\n",
                "\n",
                "region_targets = pd.DataFrame({\n",
                "    'Region': ['North', 'South', 'East', 'West'],\n",
                "    'Target': [50000, 45000, 55000, 40000],\n",
                "    'Manager': ['John', 'Sarah', 'Mike', 'Lisa']\n",
                "})\n",
                "\n",
                "print(\"=== Product Info ===\")\n",
                "print(product_info)\n",
                "print(\"\\n=== Region Targets ===\")\n",
                "print(region_targets)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Merge sales data with product info\n",
                "print(\"=== Merged: Sales + Product Cost ===\")\n",
                "merged = pd.merge(sales_data, product_info[['Product', 'Cost']], on='Product', how='left')\n",
                "merged['Profit'] = merged['Revenue'] - (merged['Cost'] * merged['Units_Sold'])\n",
                "print(merged[['Product', 'Revenue', 'Cost', 'Units_Sold', 'Profit']].head(10))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Merge types explained\n",
                "print(\"=== Merge Types ===\")\n",
                "print(\"â€¢ INNER: Only matching rows (default)\")\n",
                "print(\"â€¢ LEFT:  All rows from left table + matching from right\")\n",
                "print(\"â€¢ RIGHT: All rows from right table + matching from left\")\n",
                "print(\"â€¢ OUTER: All rows from both tables\")\n",
                "\n",
                "# Example: Add region manager to sales data\n",
                "sales_with_manager = pd.merge(sales_data, region_targets, on='Region', how='left')\n",
                "print(\"\\n=== Sales with Manager Info ===\")\n",
                "print(sales_with_manager[['Date', 'Region', 'Manager', 'Revenue', 'Target']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. The Apply Function\n",
                "\n",
                "Apply custom functions to your data - extremely powerful for complex transformations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply to a single column\n",
                "def categorize_revenue(revenue):\n",
                "    if revenue < 1000:\n",
                "        return 'Low'\n",
                "    elif revenue < 5000:\n",
                "        return 'Medium'\n",
                "    else:\n",
                "        return 'High'\n",
                "\n",
                "sales_data['Revenue_Category'] = sales_data['Revenue'].apply(categorize_revenue)\n",
                "print(\"=== Revenue Categories ===\")\n",
                "print(sales_data['Revenue_Category'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply with lambda (for simple operations)\n",
                "sales_data['Revenue_K'] = sales_data['Revenue'].apply(lambda x: f\"${x/1000:.1f}K\")\n",
                "print(\"=== Revenue in Thousands ===\")\n",
                "print(sales_data[['Revenue', 'Revenue_K', 'Revenue_Category']].head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply to entire row (axis=1)\n",
                "def create_summary(row):\n",
                "    return f\"{row['Salesperson']} sold {row['Units_Sold']} {row['Product']}(s) in {row['Region']}\"\n",
                "\n",
                "sales_data['Summary'] = sales_data.apply(create_summary, axis=1)\n",
                "print(\"=== Transaction Summaries ===\")\n",
                "print(sales_data['Summary'].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ðŸŽ¯ Mini Project: Complete Sales Analysis\n",
                "\n",
                "**Goal:** Analyze the sales data to find top-performing regions, products, and salespeople.\n",
                "\n",
                "Let's put everything together!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Re-create clean dataset for the project\n",
                "np.random.seed(42)\n",
                "n_records = 500\n",
                "\n",
                "regions = ['North', 'South', 'East', 'West', 'Central']\n",
                "products = ['Laptop', 'Phone', 'Tablet', 'Headphones', 'Charger', 'Monitor', 'Keyboard']\n",
                "salespeople = ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace']\n",
                "\n",
                "sales_df = pd.DataFrame({\n",
                "    'Date': pd.date_range(start='2024-01-01', periods=n_records, freq='D'),\n",
                "    'Region': np.random.choice(regions, n_records),\n",
                "    'Product': np.random.choice(products, n_records),\n",
                "    'Salesperson': np.random.choice(salespeople, n_records),\n",
                "    'Units_Sold': np.random.randint(1, 100, n_records),\n",
                "    'Unit_Price': np.random.choice([25, 50, 100, 250, 500, 750, 1000], n_records),\n",
                "    'Customer_Rating': np.random.choice([3.0, 3.5, 4.0, 4.5, 5.0, np.nan], n_records, \n",
                "                                        p=[0.1, 0.15, 0.25, 0.25, 0.15, 0.1])\n",
                "})\n",
                "\n",
                "# Calculated fields\n",
                "sales_df['Revenue'] = sales_df['Units_Sold'] * sales_df['Unit_Price']\n",
                "sales_df['Month'] = sales_df['Date'].dt.month_name()\n",
                "\n",
                "print(\"ðŸ“Š Sales Dataset Ready!\")\n",
                "print(f\"   Records: {len(sales_df)}\")\n",
                "print(f\"   Date Range: {sales_df['Date'].min().date()} to {sales_df['Date'].max().date()}\")\n",
                "print(f\"   Total Revenue: ${sales_df['Revenue'].sum():,.0f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Task 1: Handle Missing Data\n",
                "print(\"=\" * 50)\n",
                "print(\"ðŸ“‹ TASK 1: Data Quality Check\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "print(\"\\nðŸ” Missing Values:\")\n",
                "print(sales_df.isnull().sum())\n",
                "\n",
                "# Fill missing ratings with median\n",
                "median_rating = sales_df['Customer_Rating'].median()\n",
                "sales_df['Customer_Rating'] = sales_df['Customer_Rating'].fillna(median_rating)\n",
                "print(f\"\\nâœ… Filled missing ratings with median: {median_rating}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Task 2: Find Top Performing Regions\n",
                "print(\"=\" * 50)\n",
                "print(\"ðŸ† TASK 2: Top Performing Regions\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "region_performance = sales_df.groupby('Region').agg({\n",
                "    'Revenue': ['sum', 'mean', 'count'],\n",
                "    'Units_Sold': 'sum',\n",
                "    'Customer_Rating': 'mean'\n",
                "}).round(2)\n",
                "\n",
                "# Flatten column names\n",
                "region_performance.columns = ['Total_Revenue', 'Avg_Revenue', 'Transactions', 'Total_Units', 'Avg_Rating']\n",
                "region_performance = region_performance.sort_values('Total_Revenue', ascending=False)\n",
                "\n",
                "print(\"\\nðŸ“ˆ Region Performance Summary:\")\n",
                "print(region_performance)\n",
                "\n",
                "winner = region_performance.index[0]\n",
                "print(f\"\\nðŸ¥‡ TOP REGION: {winner} with ${region_performance.loc[winner, 'Total_Revenue']:,.0f} in revenue!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Task 3: Best Selling Products\n",
                "print(\"=\" * 50)\n",
                "print(\"ðŸ“¦ TASK 3: Best Selling Products\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "product_performance = sales_df.groupby('Product').agg({\n",
                "    'Revenue': 'sum',\n",
                "    'Units_Sold': 'sum',\n",
                "    'Customer_Rating': 'mean'\n",
                "}).round(2).sort_values('Revenue', ascending=False)\n",
                "\n",
                "product_performance['Revenue_Share_%'] = (product_performance['Revenue'] / product_performance['Revenue'].sum() * 100).round(1)\n",
                "\n",
                "print(\"\\nðŸ“Š Product Performance:\")\n",
                "print(product_performance)\n",
                "\n",
                "top_product = product_performance.index[0]\n",
                "print(f\"\\nðŸ† BEST SELLER: {top_product} ({product_performance.loc[top_product, 'Revenue_Share_%']}% of total revenue)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Task 4: Top Salespeople\n",
                "print(\"=\" * 50)\n",
                "print(\"ðŸ‘¥ TASK 4: Top Salespeople\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "top_salespeople = sales_df.groupby('Salesperson').agg({\n",
                "    'Revenue': 'sum',\n",
                "    'Units_Sold': 'sum',\n",
                "    'Customer_Rating': 'mean',\n",
                "    'Date': 'count'  # Number of transactions\n",
                "}).round(2)\n",
                "\n",
                "top_salespeople.columns = ['Total_Revenue', 'Total_Units', 'Avg_Rating', 'Transactions']\n",
                "top_salespeople['Avg_Sale_Value'] = (top_salespeople['Total_Revenue'] / top_salespeople['Transactions']).round(2)\n",
                "top_salespeople = top_salespeople.sort_values('Total_Revenue', ascending=False)\n",
                "\n",
                "print(\"\\nðŸŒŸ Salesperson Leaderboard:\")\n",
                "print(top_salespeople)\n",
                "\n",
                "mvp = top_salespeople.index[0]\n",
                "print(f\"\\nðŸ¥‡ MVP: {mvp} - ${top_salespeople.loc[mvp, 'Total_Revenue']:,.0f} in total sales!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Task 5: Monthly Trends\n",
                "print(\"=\" * 50)\n",
                "print(\"ðŸ“… TASK 5: Monthly Revenue Trends\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Create a proper month order\n",
                "month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
                "               'July', 'August', 'September', 'October', 'November', 'December']\n",
                "\n",
                "monthly_revenue = sales_df.groupby('Month')['Revenue'].sum()\n",
                "# Reorder by calendar month\n",
                "monthly_revenue = monthly_revenue.reindex([m for m in month_order if m in monthly_revenue.index])\n",
                "\n",
                "print(\"\\nðŸ“ˆ Revenue by Month:\")\n",
                "for month, revenue in monthly_revenue.items():\n",
                "    bar = 'â–ˆ' * int(revenue / monthly_revenue.max() * 30)\n",
                "    print(f\"{month:12} | {bar} ${revenue:>10,.0f}\")\n",
                "\n",
                "print(f\"\\nðŸ“Š Best Month: {monthly_revenue.idxmax()} (${monthly_revenue.max():,.0f})\")\n",
                "print(f\"ðŸ“‰ Slowest Month: {monthly_revenue.idxmin()} (${monthly_revenue.min():,.0f})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Task 6: Cross-Analysis (Region x Product)\n",
                "print(\"=\" * 50)\n",
                "print(\"ðŸ”€ TASK 6: Region-Product Matrix\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "pivot_table = sales_df.pivot_table(\n",
                "    values='Revenue', \n",
                "    index='Region', \n",
                "    columns='Product', \n",
                "    aggfunc='sum',\n",
                "    fill_value=0\n",
                ")\n",
                "\n",
                "print(\"\\nðŸ’° Revenue by Region & Product:\")\n",
                "print(pivot_table.round(0).astype(int))\n",
                "\n",
                "# Find the best combination\n",
                "best_combo = pivot_table.stack().idxmax()\n",
                "best_value = pivot_table.stack().max()\n",
                "print(f\"\\nðŸŽ¯ Best Combination: {best_combo[0]} - {best_combo[1]} = ${best_value:,.0f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Final Summary Report\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"ðŸŽ‰ SALES ANALYSIS EXECUTIVE SUMMARY\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "total_revenue = sales_df['Revenue'].sum()\n",
                "total_units = sales_df['Units_Sold'].sum()\n",
                "avg_rating = sales_df['Customer_Rating'].mean()\n",
                "\n",
                "print(f\"\"\"\n",
                "ðŸ“Š OVERALL METRICS:\n",
                "   â€¢ Total Revenue: ${total_revenue:,.0f}\n",
                "   â€¢ Total Units Sold: {total_units:,}\n",
                "   â€¢ Average Customer Rating: {avg_rating:.2f}/5.0\n",
                "   â€¢ Total Transactions: {len(sales_df)}\n",
                "\n",
                "ðŸ† TOP PERFORMERS:\n",
                "   â€¢ Best Region: {region_performance.index[0]}\n",
                "   â€¢ Best Product: {product_performance.index[0]}\n",
                "   â€¢ Top Salesperson: {top_salespeople.index[0]}\n",
                "   â€¢ Best Month: {monthly_revenue.idxmax()}\n",
                "\n",
                "ðŸ’¡ KEY INSIGHTS:\n",
                "   â€¢ {region_performance.index[0]} region generates {(region_performance.iloc[0]['Total_Revenue']/total_revenue*100):.1f}% of all revenue\n",
                "   â€¢ {product_performance.index[0]} is the revenue leader with {product_performance.iloc[0]['Revenue_Share_%']}% share\n",
                "   â€¢ {top_salespeople.index[0]} leads the team with ${top_salespeople.iloc[0]['Total_Revenue']:,.0f} in sales\n",
                "\"\"\")\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"âœ… Day 4 Complete! You've mastered Pandas fundamentals!\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ðŸŽ¯ Practice Exercises\n",
                "\n",
                "Try these on your own:\n",
                "\n",
                "1. **Filter high-value transactions**: Find all sales where Revenue > $5,000 AND Rating >= 4.5\n",
                "2. **Create a new metric**: Add a `Performance_Score` column that combines Revenue and Rating\n",
                "3. **Time analysis**: Find which day of the week has the highest average sales\n",
                "4. **Data export**: Save the analysis results to a CSV file using `df.to_csv('filename.csv')`\n",
                "\n",
                "---\n",
                "\n",
                "## ðŸ“š Key Takeaways\n",
                "\n",
                "| Concept | Key Methods |\n",
                "|---------|-------------|\n",
                "| **Loading Data** | `pd.read_csv()`, `pd.read_excel()` |\n",
                "| **Inspecting** | `.head()`, `.info()`, `.describe()`, `.shape` |\n",
                "| **Missing Values** | `.isnull()`, `.dropna()`, `.fillna()` |\n",
                "| **Selection** | `df['col']`, `df[['col1', 'col2']]`, `.loc[]`, `.iloc[]` |\n",
                "| **Filtering** | `df[df['col'] > value]`, `&`, `|` |\n",
                "| **Aggregation** | `.groupby()`, `.agg()`, `.sum()`, `.mean()` |\n",
                "| **Merging** | `pd.merge()`, `pd.concat()` |\n",
                "| **Transformation** | `.apply()`, lambda functions |\n",
                "\n",
                "---\n",
                "\n",
                "**Next Up:** Day 5 - Data Visualization with Matplotlib & Seaborn! ðŸ“Š"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
