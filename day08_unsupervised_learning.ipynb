{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 8: Unsupervised Learning\n",
                "\n",
                "Today we explore **Unsupervised Learning** - finding patterns in data WITHOUT labels!\n",
                "\n",
                "### Topics Covered:\n",
                "1. Supervised vs Unsupervised Learning\n",
                "2. K-Means Clustering\n",
                "3. The Elbow Method\n",
                "4. Principal Component Analysis (PCA)\n",
                "5. **Mini Project: Customer Segmentation**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import silhouette_score\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "np.random.seed(42)\n",
                "print(\"Libraries loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Supervised vs Unsupervised\n",
                "\n",
                "| Aspect | Supervised | Unsupervised |\n",
                "|--------|------------|---------------|\n",
                "| **Labels** | Has labels (y) | No labels |\n",
                "| **Goal** | Predict outcomes | Find patterns |\n",
                "| **Examples** | Classification, Regression | Clustering, Dimensionality Reduction |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize the difference\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Supervised - has labels\n",
                "np.random.seed(42)\n",
                "x1 = np.random.normal(2, 0.5, 50)\n",
                "y1 = np.random.normal(2, 0.5, 50)\n",
                "x2 = np.random.normal(4, 0.5, 50)\n",
                "y2 = np.random.normal(4, 0.5, 50)\n",
                "\n",
                "axes[0].scatter(x1, y1, c='#3498db', label='Class A', s=60)\n",
                "axes[0].scatter(x2, y2, c='#e74c3c', label='Class B', s=60)\n",
                "axes[0].set_title('Supervised: Data HAS Labels', fontsize=12, fontweight='bold')\n",
                "axes[0].legend()\n",
                "\n",
                "# Unsupervised - no labels\n",
                "axes[1].scatter(np.concatenate([x1, x2]), np.concatenate([y1, y2]), c='gray', s=60)\n",
                "axes[1].set_title('Unsupervised: Find the Groups!', fontsize=12, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. K-Means Clustering\n",
                "\n",
                "**Goal:** Partition data into K clusters where each point belongs to the nearest centroid.\n",
                "\n",
                "**Algorithm:**\n",
                "1. Choose K (number of clusters)\n",
                "2. Initialize K random centroids\n",
                "3. Assign each point to nearest centroid\n",
                "4. Update centroids to cluster means\n",
                "5. Repeat until convergence"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create sample clustered data\n",
                "from sklearn.datasets import make_blobs\n",
                "\n",
                "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.8, random_state=42)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.scatter(X[:, 0], X[:, 1], c='gray', s=50, alpha=0.6)\n",
                "plt.title('Raw Data - Can You See the Clusters?', fontsize=12, fontweight='bold')\n",
                "plt.xlabel('Feature 1')\n",
                "plt.ylabel('Feature 2')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply K-Means\n",
                "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
                "clusters = kmeans.fit_predict(X)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "scatter = plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', s=50, alpha=0.7)\n",
                "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
                "            c='red', marker='X', s=200, edgecolors='black', linewidth=2, label='Centroids')\n",
                "plt.title('K-Means Clustering (K=4)', fontsize=12, fontweight='bold')\n",
                "plt.xlabel('Feature 1')\n",
                "plt.ylabel('Feature 2')\n",
                "plt.legend()\n",
                "plt.colorbar(scatter, label='Cluster')\n",
                "plt.show()\n",
                "\n",
                "print(f\"Cluster Centers:\\n{kmeans.cluster_centers_}\")\n",
                "print(f\"\\nInertia (within-cluster sum of squares): {kmeans.inertia_:.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize K-Means steps\n",
                "fig, axes = plt.subplots(2, 3, figsize=(14, 9))\n",
                "\n",
                "for i, ax in enumerate(axes.flatten()):\n",
                "    if i == 0:\n",
                "        ax.scatter(X[:, 0], X[:, 1], c='gray', s=30)\n",
                "        ax.set_title('Step 1: Raw Data')\n",
                "    else:\n",
                "        km = KMeans(n_clusters=4, random_state=42, n_init=1, max_iter=i)\n",
                "        km.fit(X)\n",
                "        ax.scatter(X[:, 0], X[:, 1], c=km.labels_, cmap='viridis', s=30)\n",
                "        ax.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], \n",
                "                   c='red', marker='X', s=150, edgecolors='black')\n",
                "        ax.set_title(f'Iteration {i}')\n",
                "\n",
                "plt.suptitle('K-Means Algorithm Steps', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. The Elbow Method - Finding Optimal K\n",
                "\n",
                "**Problem:** How do we choose the right number of clusters?\n",
                "\n",
                "**Solution:** Plot inertia vs K and look for the \"elbow\" point."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Elbow Method\n",
                "inertias = []\n",
                "silhouettes = []\n",
                "K_range = range(2, 11)\n",
                "\n",
                "for k in K_range:\n",
                "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
                "    km.fit(X)\n",
                "    inertias.append(km.inertia_)\n",
                "    silhouettes.append(silhouette_score(X, km.labels_))\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Elbow Plot\n",
                "axes[0].plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
                "axes[0].axvline(x=4, color='r', linestyle='--', label='Optimal K=4')\n",
                "axes[0].set_title('Elbow Method', fontsize=12, fontweight='bold')\n",
                "axes[0].set_xlabel('Number of Clusters (K)')\n",
                "axes[0].set_ylabel('Inertia')\n",
                "axes[0].legend()\n",
                "\n",
                "# Silhouette Score\n",
                "axes[1].plot(K_range, silhouettes, 'go-', linewidth=2, markersize=8)\n",
                "axes[1].axvline(x=4, color='r', linestyle='--', label='Optimal K=4')\n",
                "axes[1].set_title('Silhouette Score (Higher = Better)', fontsize=12, fontweight='bold')\n",
                "axes[1].set_xlabel('Number of Clusters (K)')\n",
                "axes[1].set_ylabel('Silhouette Score')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"Best K by Silhouette: {K_range[np.argmax(silhouettes)]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. PCA - Dimensionality Reduction\n",
                "\n",
                "**Goal:** Reduce features while keeping most information.\n",
                "\n",
                "**Use Cases:**\n",
                "- Visualization (reduce to 2D/3D)\n",
                "- Speed up ML algorithms\n",
                "- Remove noise and redundancy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create high-dimensional data\n",
                "np.random.seed(42)\n",
                "n_samples = 200\n",
                "\n",
                "# 6 features, but really only 2 dimensions of variance\n",
                "X_pca = np.random.randn(n_samples, 2)\n",
                "X_high = np.column_stack([\n",
                "    X_pca[:, 0],\n",
                "    X_pca[:, 1],\n",
                "    X_pca[:, 0] + np.random.randn(n_samples) * 0.1,\n",
                "    X_pca[:, 1] + np.random.randn(n_samples) * 0.1,\n",
                "    X_pca[:, 0] * 2 + np.random.randn(n_samples) * 0.2,\n",
                "    X_pca[:, 1] * 0.5 + np.random.randn(n_samples) * 0.1\n",
                "])\n",
                "\n",
                "print(f\"Original shape: {X_high.shape} (6 features)\")\n",
                "\n",
                "# Apply PCA\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X_high)\n",
                "\n",
                "pca = PCA()\n",
                "X_pca_result = pca.fit_transform(X_scaled)\n",
                "\n",
                "# Explained variance\n",
                "print(f\"\\nExplained Variance Ratio:\")\n",
                "for i, var in enumerate(pca.explained_variance_ratio_):\n",
                "    print(f\"  PC{i+1}: {var*100:.1f}%\")\n",
                "print(f\"\\nTotal with 2 components: {sum(pca.explained_variance_ratio_[:2])*100:.1f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize PCA\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Cumulative Variance\n",
                "cumulative = np.cumsum(pca.explained_variance_ratio_)\n",
                "axes[0].bar(range(1, 7), pca.explained_variance_ratio_, alpha=0.7, label='Individual')\n",
                "axes[0].plot(range(1, 7), cumulative, 'ro-', label='Cumulative')\n",
                "axes[0].axhline(y=0.95, color='g', linestyle='--', label='95% threshold')\n",
                "axes[0].set_title('Explained Variance by Component', fontsize=12, fontweight='bold')\n",
                "axes[0].set_xlabel('Principal Component')\n",
                "axes[0].set_ylabel('Explained Variance Ratio')\n",
                "axes[0].legend()\n",
                "\n",
                "# 2D visualization\n",
                "axes[1].scatter(X_pca_result[:, 0], X_pca_result[:, 1], c='#3498db', alpha=0.6)\n",
                "axes[1].set_title('Data in 2D (PCA)', fontsize=12, fontweight='bold')\n",
                "axes[1].set_xlabel('PC1')\n",
                "axes[1].set_ylabel('PC2')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Mini Project: Customer Segmentation\n",
                "\n",
                "**Goal:** Segment mall customers based on their spending habits."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create customer dataset\n",
                "np.random.seed(42)\n",
                "n = 200\n",
                "\n",
                "# 5 customer segments\n",
                "segments = [\n",
                "    {'age': (20, 5), 'income': (20, 5), 'score': (80, 10), 'n': 40},   # Young high spenders\n",
                "    {'age': (25, 5), 'income': (80, 15), 'score': (20, 10), 'n': 40},  # Young high income, low spend\n",
                "    {'age': (45, 10), 'income': (50, 15), 'score': (50, 15), 'n': 50}, # Middle aged moderate\n",
                "    {'age': (55, 10), 'income': (70, 20), 'score': (80, 10), 'n': 35}, # Older high spenders\n",
                "    {'age': (40, 10), 'income': (30, 10), 'score': (30, 10), 'n': 35}, # Moderate income low spend\n",
                "]\n",
                "\n",
                "data = []\n",
                "for seg in segments:\n",
                "    for _ in range(seg['n']):\n",
                "        data.append({\n",
                "            'Age': np.random.normal(seg['age'][0], seg['age'][1]),\n",
                "            'Annual_Income': np.random.normal(seg['income'][0], seg['income'][1]),\n",
                "            'Spending_Score': np.random.normal(seg['score'][0], seg['score'][1])\n",
                "        })\n",
                "\n",
                "customers = pd.DataFrame(data)\n",
                "customers['Age'] = customers['Age'].clip(18, 70).astype(int)\n",
                "customers['Annual_Income'] = customers['Annual_Income'].clip(10, 150).astype(int)\n",
                "customers['Spending_Score'] = customers['Spending_Score'].clip(1, 100).astype(int)\n",
                "customers['CustomerID'] = range(1, len(customers) + 1)\n",
                "customers = customers[['CustomerID', 'Age', 'Annual_Income', 'Spending_Score']]\n",
                "\n",
                "print(\" MALL CUSTOMER DATASET\")\n",
                "print(f\"Total Customers: {len(customers)}\")\n",
                "print(customers.head(10))\n",
                "print(\"\\nStatistics:\")\n",
                "print(customers.describe().round(1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# EDA\n",
                "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
                "\n",
                "axes[0].hist(customers['Age'], bins=20, color='#3498db', edgecolor='white')\n",
                "axes[0].set_title('Age Distribution')\n",
                "axes[0].set_xlabel('Age')\n",
                "\n",
                "axes[1].hist(customers['Annual_Income'], bins=20, color='#2ecc71', edgecolor='white')\n",
                "axes[1].set_title('Income Distribution (K$)')\n",
                "axes[1].set_xlabel('Annual Income')\n",
                "\n",
                "axes[2].hist(customers['Spending_Score'], bins=20, color='#e74c3c', edgecolor='white')\n",
                "axes[2].set_title('Spending Score Distribution')\n",
                "axes[2].set_xlabel('Spending Score (1-100)')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find optimal K\n",
                "X_cluster = customers[['Annual_Income', 'Spending_Score']]\n",
                "\n",
                "inertias = []\n",
                "sil_scores = []\n",
                "K_range = range(2, 11)\n",
                "\n",
                "for k in K_range:\n",
                "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
                "    km.fit(X_cluster)\n",
                "    inertias.append(km.inertia_)\n",
                "    sil_scores.append(silhouette_score(X_cluster, km.labels_))\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "axes[0].plot(K_range, inertias, 'bo-', linewidth=2)\n",
                "axes[0].axvline(x=5, color='r', linestyle='--')\n",
                "axes[0].set_title('Elbow Method')\n",
                "axes[0].set_xlabel('K')\n",
                "axes[0].set_ylabel('Inertia')\n",
                "\n",
                "axes[1].plot(K_range, sil_scores, 'go-', linewidth=2)\n",
                "axes[1].axvline(x=5, color='r', linestyle='--')\n",
                "axes[1].set_title('Silhouette Score')\n",
                "axes[1].set_xlabel('K')\n",
                "axes[1].set_ylabel('Score')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"Optimal K: 5 (by elbow and silhouette analysis)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply K-Means with K=5\n",
                "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
                "customers['Cluster'] = kmeans.fit_predict(X_cluster)\n",
                "\n",
                "# Visualize clusters\n",
                "plt.figure(figsize=(10, 7))\n",
                "scatter = plt.scatter(customers['Annual_Income'], customers['Spending_Score'], \n",
                "                       c=customers['Cluster'], cmap='viridis', s=80, alpha=0.7)\n",
                "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], \n",
                "            c='red', marker='X', s=300, edgecolors='black', linewidth=2)\n",
                "plt.title('Customer Segments', fontsize=14, fontweight='bold')\n",
                "plt.xlabel('Annual Income (K$)')\n",
                "plt.ylabel('Spending Score (1-100)')\n",
                "plt.colorbar(scatter, label='Cluster')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze Clusters\n",
                "cluster_analysis = customers.groupby('Cluster').agg({\n",
                "    'Age': 'mean',\n",
                "    'Annual_Income': 'mean',\n",
                "    'Spending_Score': 'mean',\n",
                "    'CustomerID': 'count'\n",
                "}).round(1)\n",
                "cluster_analysis.columns = ['Avg_Age', 'Avg_Income', 'Avg_Spending', 'Count']\n",
                "\n",
                "# Name the segments\n",
                "segment_names = {\n",
                "    0: 'Moderate All',\n",
                "    1: 'High Income Low Spend',\n",
                "    2: 'Young Budget Shoppers',\n",
                "    3: 'High Income High Spend',\n",
                "    4: 'Low Income Low Spend'\n",
                "}\n",
                "\n",
                "cluster_analysis['Segment'] = cluster_analysis.index.map(segment_names)\n",
                "\n",
                "print(\" CUSTOMER SEGMENTS\")\n",
                "print(\"=\"*60)\n",
                "print(cluster_analysis)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Detailed segment visualization\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Segment profiles\n",
                "cluster_analysis[['Avg_Income', 'Avg_Spending']].plot(kind='bar', ax=axes[0], \n",
                "                                                       color=['#3498db', '#e74c3c'])\n",
                "axes[0].set_title('Segment Profiles', fontweight='bold')\n",
                "axes[0].set_xlabel('Cluster')\n",
                "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
                "axes[0].legend(['Avg Income', 'Avg Spending'])\n",
                "\n",
                "# Segment sizes\n",
                "colors = plt.cm.viridis(np.linspace(0.2, 0.8, 5))\n",
                "axes[1].pie(cluster_analysis['Count'], labels=[segment_names[i] for i in range(5)],\n",
                "            autopct='%1.1f%%', colors=colors, explode=[0.02]*5)\n",
                "axes[1].set_title('Segment Distribution', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Business Recommendations\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\" BUSINESS INSIGHTS & RECOMMENDATIONS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "recommendations = {\n",
                "    'High Income High Spend': 'VIP treatment, exclusive products, loyalty rewards',\n",
                "    'High Income Low Spend': 'Target with premium campaigns, needs convincing',\n",
                "    'Young Budget Shoppers': 'Discounts, trendy items, social media marketing',\n",
                "    'Moderate All': 'Standard promotions, balanced offerings',\n",
                "    'Low Income Low Spend': 'Budget products, clearance sales'\n",
                "}\n",
                "\n",
                "for segment, rec in recommendations.items():\n",
                "    print(f\"\\n {segment}:\")\n",
                "    print(f\"   Strategy: {rec}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Final Summary\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\" DAY 8 COMPLETE!\")\n",
                "print(\"=\"*60)\n",
                "print(\"\"\"\n",
                " KEY TAKEAWAYS:\n",
                "\n",
                " 1. K-MEANS CLUSTERING\n",
                "    - Partitions data into K groups\n",
                "    - Uses centroids and distances\n",
                "    - Need to choose K beforehand\n",
                "\n",
                " 2. ELBOW METHOD\n",
                "    - Plot inertia vs K\n",
                "    - Look for the \"elbow\" bend\n",
                "    - Silhouette score helps confirm\n",
                "\n",
                " 3. PCA\n",
                "    - Reduces dimensions\n",
                "    - Keeps most variance\n",
                "    - Great for visualization\n",
                "\n",
                " 4. CUSTOMER SEGMENTATION\n",
                "    - Real business application\n",
                "    - Enables targeted marketing\n",
                "    - Data-driven decisions\n",
                "\"\"\")\n",
                "print(\"=\"*60)\n",
                "print(\" Next: Day 9 - Model Evaluation & Optimization!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Practice Exercises\n",
                "\n",
                "1. Try clustering with 3 features (include Age)\n",
                "2. Apply PCA before clustering\n",
                "3. Experiment with different K values\n",
                "4. Try hierarchical clustering (`scipy.cluster.hierarchy`)\n",
                "\n",
                "---\n",
                "**Next Up:** Day 9 - Model Evaluation & Hyperparameter Tuning!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.13.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
